{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Neural network\n",
        "\n",
        "Here we implement a Siamese neural network to test how deep learning approach works with face recognition when having small amount of data."
      ],
      "metadata": {
        "id": "Nf9R3WJaxCCD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GtX_ugC8RyGx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8bbb2039-4a12-46f9-834d-cfb1f9052fc1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow==2.4.1\n",
            "  Downloading tensorflow-2.4.1-cp37-cp37m-manylinux2010_x86_64.whl (394.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 394.3 MB 10 kB/s \n",
            "\u001b[?25hCollecting tensorflow-gpu==2.4.1\n",
            "  Downloading tensorflow_gpu-2.4.1-cp37-cp37m-manylinux2010_x86_64.whl (394.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 394.3 MB 16 kB/s \n",
            "\u001b[?25hRequirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (4.1.2.30)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (3.2.2)\n",
            "Collecting typing-extensions~=3.7.4\n",
            "  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
            "Collecting absl-py~=0.10\n",
            "  Downloading absl_py-0.15.0-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 46.8 MB/s \n",
            "\u001b[?25hCollecting grpcio~=1.32.0\n",
            "  Downloading grpcio-1.32.0-cp37-cp37m-manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 44.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (3.3.0)\n",
            "Collecting tensorflow-estimator<2.5.0,>=2.4.0\n",
            "  Downloading tensorflow_estimator-2.4.0-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[K     |████████████████████████████████| 462 kB 88.0 MB/s \n",
            "\u001b[?25hCollecting h5py~=2.10.0\n",
            "  Downloading h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 51.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (2.8.0)\n",
            "Collecting gast==0.3.3\n",
            "  Downloading gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (3.17.3)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (1.1.2)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (1.1.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (0.37.1)\n",
            "Collecting numpy~=1.19.2\n",
            "  Downloading numpy-1.19.5-cp37-cp37m-manylinux2010_x86_64.whl (14.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 14.8 MB 45.5 MB/s \n",
            "\u001b[?25hCollecting wrapt~=1.12.1\n",
            "  Downloading wrapt-1.12.1.tar.gz (27 kB)\n",
            "Collecting flatbuffers~=1.12.0\n",
            "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (0.2.0)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (1.15.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (1.6.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (0.6.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (1.35.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (3.3.7)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (57.4.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (0.4.6)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4.1) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow==2.4.1) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.4->tensorflow==2.4.1) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (2022.5.18.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4.1) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.4.2)\n",
            "Building wheels for collected packages: wrapt\n",
            "  Building wheel for wrapt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wrapt: filename=wrapt-1.12.1-cp37-cp37m-linux_x86_64.whl size=68720 sha256=4ded0a83f3693585790a36f24438ddf39f941d797248a2bb497853ded39176ea\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/76/4c/aa25851149f3f6d9785f6c869387ad82b3fd37582fa8147ac6\n",
            "Successfully built wrapt\n",
            "Installing collected packages: typing-extensions, numpy, grpcio, absl-py, wrapt, tensorflow-estimator, h5py, gast, flatbuffers, tensorflow-gpu, tensorflow\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing-extensions 4.2.0\n",
            "    Uninstalling typing-extensions-4.2.0:\n",
            "      Successfully uninstalled typing-extensions-4.2.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.6\n",
            "    Uninstalling numpy-1.21.6:\n",
            "      Successfully uninstalled numpy-1.21.6\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.46.1\n",
            "    Uninstalling grpcio-1.46.1:\n",
            "      Successfully uninstalled grpcio-1.46.1\n",
            "  Attempting uninstall: absl-py\n",
            "    Found existing installation: absl-py 1.0.0\n",
            "    Uninstalling absl-py-1.0.0:\n",
            "      Successfully uninstalled absl-py-1.0.0\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.14.1\n",
            "    Uninstalling wrapt-1.14.1:\n",
            "      Successfully uninstalled wrapt-1.14.1\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.8.0\n",
            "    Uninstalling tensorflow-estimator-2.8.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.8.0\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.1.0\n",
            "    Uninstalling h5py-3.1.0:\n",
            "      Successfully uninstalled h5py-3.1.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.5.3\n",
            "    Uninstalling gast-0.5.3:\n",
            "      Successfully uninstalled gast-0.5.3\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 2.0\n",
            "    Uninstalling flatbuffers-2.0:\n",
            "      Successfully uninstalled flatbuffers-2.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.8.0+zzzcolab20220506162203\n",
            "    Uninstalling tensorflow-2.8.0+zzzcolab20220506162203:\n",
            "      Successfully uninstalled tensorflow-2.8.0+zzzcolab20220506162203\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "xarray-einstats 0.2.2 requires numpy>=1.21, but you have numpy 1.19.5 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed absl-py-0.15.0 flatbuffers-1.12 gast-0.3.3 grpcio-1.32.0 h5py-2.10.0 numpy-1.19.5 tensorflow-2.4.1 tensorflow-estimator-2.4.0 tensorflow-gpu-2.4.1 typing-extensions-3.7.4.3 wrapt-1.12.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "typing_extensions"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install tensorflow==2.4.1 tensorflow-gpu==2.4.1 opencv-python matplotlib "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import dependencies and set memory growth using gpu\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import random\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.datasets import fetch_lfw_people\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Layer, Conv2D, Dense, MaxPooling2D, Input, Flatten\n",
        "import tensorflow as tf\n",
        "\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "for gpu in gpus:\n",
        "  tf.config.experimental.set_memory_growth(gpu, True)\n",
        "\n",
        "#Create folders for positive, negative and anchor images to train and test the network\n",
        "\n",
        "POS_PATH = os.path.join('data', 'positive')\n",
        "NEG_PATH = os.path.join('data', 'negative')\n",
        "ANC_PATH = os.path.join('data', 'anchor')\n",
        "\n",
        "os.makedirs(POS_PATH)\n",
        "os.makedirs(NEG_PATH)\n",
        "os.makedirs(ANC_PATH)\n",
        "\n",
        "# Unpack the database\n",
        "!tar -xf lfw.tgz\n",
        "\n",
        "# Here are the names of people whose number of photos of the database is >= 60. \n",
        "# We take this number because we want to test our neural network \n",
        "# on the same people we used in the Eigenfaces algorithm. \n",
        "\n",
        "lst_names = ['Ariel_Sharon', 'Colin_Powell', 'Donald_Rumsfeld', \\\n",
        "             'George_W_Bush', 'Gerhard_Schroeder', 'Hugo_Chavez', \\\n",
        "             'Junichiro_Koizumi', 'Tony_Blair']\n",
        "\n",
        "\n",
        "# Fill positive, negative and anchor folders with data from the LFW database\n",
        "# (people who have more than 60 photos)\n",
        "\n",
        "for directory in os.listdir('lfw'):\n",
        "  if os.path.basename(directory) in lst_names:\n",
        "\n",
        "    POS_PATH_DIR = os.path.join('data', 'positive', directory)\n",
        "    os.makedirs(POS_PATH_DIR)\n",
        "    lstdir = os.listdir(os.path.join('lfw', directory))\n",
        "    \n",
        "    for file in lstdir[:len(lstdir)//2]:\n",
        "      EX_PATH = os.path.join('lfw', directory, file)      \n",
        "      POS_PATH_DIR_FILE = os.path.join('data', 'positive', os.path.basename(directory), file)\n",
        "      os.replace(EX_PATH, POS_PATH_DIR_FILE)\n",
        "\n",
        "    ANC_PATH_DIR = os.path.join('data', 'anchor', os.path.basename(directory))\n",
        "    os.makedirs(ANC_PATH_DIR)\n",
        "\n",
        "    for file in lstdir[len(lstdir)//2:(len(lstdir)//2)*2]:\n",
        "      EX_PATH = os.path.join('lfw', directory, file)\n",
        "      ANC_PATH_DIR_FILE = os.path.join('data', 'anchor', os.path.basename(directory), file)\n",
        "      os.replace(EX_PATH, ANC_PATH_DIR_FILE)\n",
        "\n",
        "\n",
        "for directory in os.listdir('lfw'):\n",
        "  if os.path.basename(directory) not in lst_names:\n",
        "    lstdir = os.listdir(os.path.join('lfw', directory))\n",
        "    EX_PATH = os.path.join('lfw', directory, lstdir[0])\n",
        "    NEG_PATH_DIR_FILE = os.path.join('data', 'negative', lstdir[0])\n",
        "    os.replace(EX_PATH, NEG_PATH_DIR_FILE)\n"
      ],
      "metadata": {
        "id": "2K1E2adsTrUG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "1ebd4dfa-7dd3-4aa4-cf3b-ea74c90f30a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tar: lfw.tgz: Cannot open: No such file or directory\n",
            "tar: Error is not recoverable: exiting now\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-1ccfc8674573>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;31m# (people who have more than 60 photos)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mdirectory\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'lfw'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlst_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'lfw'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have decided to test the network only on one person (Ariel Sharon), as training on all the people who have >60 photos in the database would take too much time. Nevertheless, for each person there would be a separate training needed and we can make conclusions based on one example.\n"
      ],
      "metadata": {
        "id": "iayXT1rGuxr8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting images from directories. \n",
        "\n",
        "anchor = tf.data.Dataset.list_files('data/anchor/Ariel_Sharon/*.jpg').take(len(os.listdir('data/anchor/Ariel_Sharon')))\n",
        "positive = tf.data.Dataset.list_files('data/positive/Ariel_Sharon/*.jpg').take(len(os.listdir('data/positive/Ariel_Sharon')))\n",
        "negative = tf.data.Dataset.list_files('data/negative/*.jpg').take(len(os.listdir('data/positive/Ariel_Sharon')))\n",
        "\n",
        "# Read and preprocess (scale and resize) image\n",
        "\n",
        "def preprocess(file_path):\n",
        "    \n",
        "    byte_img = tf.io.read_file(file_path)\n",
        "    img = tf.io.decode_jpeg(byte_img)\n",
        "    img = tf.image.resize(img, (100,100))\n",
        "    img = img / 255.0\n",
        "\n",
        "    return img\n",
        "\n",
        "# Make labelled dataset with triplets -> (anchor, positive/negative, 1/0)\n",
        "\n",
        "positives = tf.data.Dataset.zip((anchor, positive, tf.data.Dataset.from_tensor_slices(tf.ones(len(anchor)))))\n",
        "negatives = tf.data.Dataset.zip((anchor, negative, tf.data.Dataset.from_tensor_slices(tf.zeros(len(anchor)))))\n",
        "data = positives.concatenate(negatives)\n",
        "\n",
        "# Preprocess triplets created in the previous function\n",
        "\n",
        "def preprocess_twin(input_img, validation_img, label):\n",
        "    return(preprocess(input_img), preprocess(validation_img), label)\n",
        "\n",
        "# Preprocess all the data\n",
        "\n",
        "data = data.map(preprocess_twin)\n",
        "data = data.cache()\n",
        "data = data.shuffle(buffer_size=104)\n",
        "\n",
        "# Split the data into train and test parts\n",
        "\n",
        "train_data = data.take(round(len(data)*.7))\n",
        "train_data = train_data.batch(8)\n",
        "train_data = train_data.prefetch(4)\n",
        "\n",
        "test_data = data.skip(round(len(data)*.7))\n",
        "test_data = test_data.take(round(len(data)*.3))\n",
        "test_data = test_data.batch(8)\n",
        "test_data = test_data.prefetch(4)\n",
        "\n"
      ],
      "metadata": {
        "id": "DpA_f3xwgHcv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform an image matrix into model with a vector of features \n",
        "\n",
        "def make_embedding(): \n",
        "    inp = Input(shape=(100,100,3), name='input_image')\n",
        "    \n",
        "    c1 = Conv2D(64, (10,10), activation='relu')(inp)\n",
        "    m1 = MaxPooling2D(64, (2,2), padding='same')(c1)\n",
        "    \n",
        "    c2 = Conv2D(128, (7,7), activation='relu')(m1)\n",
        "    m2 = MaxPooling2D(64, (2,2), padding='same')(c2)\n",
        "    \n",
        "    c3 = Conv2D(128, (4,4), activation='relu')(m2)\n",
        "    m3 = MaxPooling2D(64, (2,2), padding='same')(c3)\n",
        "    \n",
        "    c4 = Conv2D(256, (4,4), activation='relu')(m3)\n",
        "    f1 = Flatten()(c4)\n",
        "    d1 = Dense(4096, activation='sigmoid')(f1)\n",
        "    \n",
        "    return Model(inputs=[inp], outputs=[d1], name='embedding')\n",
        "\n",
        "embedding = make_embedding()\n",
        "embedding.summary()\n",
        "\n",
        "# Create class that calculates the distance between vector's points\n",
        "\n",
        "class L1Dist(Layer):\n",
        "    \n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__()\n",
        "       \n",
        "    def call(self, input_embedding, validation_embedding):\n",
        "        return tf.math.abs(input_embedding - validation_embedding)"
      ],
      "metadata": {
        "id": "exfMn9s_gsc-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this block of code we build and train our Siamese neural network. As we have already run and trained it, there s no need to run this block of code. In the following chunks we use previously saved file with neural network 'siamesemodelv2.h5'. "
      ],
      "metadata": {
        "id": "pPn2vuSLsasV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_siamese_model(): \n",
        "    \n",
        "    # Anchor image \n",
        "    input_image = Input(name='input_img', shape=(100,100,3))\n",
        "    \n",
        "    # Validation image (positive/negative)\n",
        "    validation_image = Input(name='validation_img', shape=(100,100,3))\n",
        "    \n",
        "    # Calculate distances\n",
        "    siamese_layer = L1Dist()\n",
        "    siamese_layer._name = 'distance'\n",
        "    distances = siamese_layer(embedding(input_image), embedding(validation_image))\n",
        "    \n",
        "    # Classify\n",
        "    classifier = Dense(1, activation='sigmoid')(distances)\n",
        "    \n",
        "    return Model(inputs=[input_image, validation_image], outputs=classifier, name='SiameseNetwork')\n",
        "\n",
        "# Calculate possible accuracy and optimize model\n",
        "\n",
        "binary_cross_loss = tf.losses.BinaryCrossentropy()\n",
        "opt = tf.keras.optimizers.Adam(1e-4) # 0.0001 \n",
        "\n",
        "# os.makedirs(os.path.join('training_checkpoints'))\n",
        "\n",
        "siamese_model = make_siamese_model()\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, 'ckpt')\n",
        "checkpoint = tf.train.Checkpoint(opt=opt, siamese_model=siamese_model)\n",
        "\n",
        "# Train the model\n",
        "\n",
        "@tf.function\n",
        "def train_step(batch):\n",
        "    \n",
        "    with tf.GradientTape() as tape:     \n",
        "        X = batch[:2]\n",
        "        y = batch[2]\n",
        "        \n",
        "        yhat = siamese_model(X, training=True)\n",
        "        loss = binary_cross_loss(y, yhat)\n",
        "        \n",
        "    grad = tape.gradient(loss, siamese_model.trainable_variables)\n",
        "    opt.apply_gradients(zip(grad, siamese_model.trainable_variables))\n",
        "        \n",
        "    return loss\n",
        "\n",
        "def train(data, EPOCHS):\n",
        "\n",
        "    # Iterate over all of the data exactly once \n",
        "    \n",
        "    for epoch in range(1, EPOCHS+1):\n",
        "        print('\\n Epoch {}/{}'.format(epoch, EPOCHS))\n",
        "        progbar = tf.keras.utils.Progbar(len(data))\n",
        "        \n",
        "        r = Recall()\n",
        "        p = Precision()\n",
        "        \n",
        "        # Iterate over batches\n",
        "        for idx, batch in enumerate(data):\n",
        "\n",
        "            loss = train_step(batch)\n",
        "            yhat = siamese_model.predict(batch[:2])\n",
        "            r.update_state(batch[2], yhat)\n",
        "            p.update_state(batch[2], yhat) \n",
        "            progbar.update(idx+1)\n",
        "        print(loss.numpy(), r.result().numpy(), p.result().numpy())\n",
        "        \n",
        "        # Save checkpoints\n",
        "        if epoch % 10 == 0: \n",
        "            checkpoint.save(file_prefix=checkpoint_prefix)\n",
        "\n",
        "\n",
        "# We iterate over all of the data 50 times while training, \n",
        "# and each time through every batch \n",
        "\n",
        "EPOCHS = 50\n",
        "train(train_data, EPOCHS)\n"
      ],
      "metadata": {
        "id": "Gz7eQFgaYqB9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing Precision and Recall to evaluate results\n",
        "\n",
        "from tensorflow.keras.metrics import Precision, Recall\n",
        "\n",
        "# Get a batch of test data\n",
        "\n",
        "test_input, test_val, y_true = test_data.as_numpy_iterator().next()\n",
        "y_hat = siamese_model.predict([test_input, test_val])\n",
        "\n",
        "# Evaluating the results \n",
        "\n",
        "y_hat = [1 if prediction > 0.5 else 0 for prediction in y_hat]\n",
        "\n",
        "m = Recall()\n",
        "m.update_state(y_true, y_hat)\n",
        "m.result().numpy()\n",
        "\n",
        "m = Precision()\n",
        "\n",
        "m.update_state(y_true, y_hat)\n",
        "\n",
        "m.result().numpy()\n",
        "\n",
        "r = Recall()\n",
        "p = Precision()\n",
        "\n",
        "for test_input, test_val, y_true in test_data.as_numpy_iterator():\n",
        "    yhat = siamese_model.predict([test_input, test_val])\n",
        "    r.update_state(y_true, yhat)\n",
        "    p.update_state(y_true,yhat) \n",
        "    \n",
        "print('Accuracy:')\n",
        "print(r.result().numpy(), p.result().numpy())\n",
        "\n",
        "# Make plots\n",
        "plt.figure(figsize=(10,8))\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(test_input[0])\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(test_val[0])\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# # Save model\n",
        "# siamese_model.save('siamesemodelv2.h5')"
      ],
      "metadata": {
        "id": "sFAhqauyRr2Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reload model \n",
        "siamese_model = tf.keras.models.load_model('siamesemodelv2.h5', \n",
        "                                   custom_objects={'L1Dist':L1Dist, 'BinaryCrossentropy':tf.losses.BinaryCrossentropy})\n",
        "# Make predictions with reloaded model\n",
        "siamese_model.predict([test_input, test_val])\n",
        "\n",
        "# View model summary\n",
        "siamese_model.summary()"
      ],
      "metadata": {
        "id": "geo7vP2Uf3qG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion\n",
        "\n",
        "After testing our neural network several times, we can see that Siamese neural network and deep learning approach in general works not well with small amounts of data. As we have only 38 photos in positive and anchor folders, the network did not have enough data to train and work good enough and accuracy of recognition was not high. As a result, we got errors in facial recognition quite often. From this we can conclude that Eigenfaces approach works much better on small amounts of data. "
      ],
      "metadata": {
        "id": "0bzKRY5Cyu7L"
      }
    }
  ]
}